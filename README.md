# ğŸ¤– TechStore AI Support - Full-Stack RAG System

A production-ready, full-stack **Retrieval-Augmented Generation (RAG)** customer support system built with **FastAPI**, **React**, and **multi-LLM support** (OpenAI, Anthropic Claude, Google Gemini).

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.10+-blue.svg)
![React](https://img.shields.io/badge/react-18.2+-blue.svg)
![FastAPI](https://img.shields.io/badge/fastapi-0.109+-green.svg)

## ğŸ“‹ Table of Contents

- [Features](#-features)
- [Tech Stack](#-tech-stack)
- [Architecture](#-architecture)
- [Screenshots](#-screenshots)
- [Getting Started](#-getting-started)
- [Configuration](#-configuration)
- [Usage](#-usage)
- [API Documentation](#-api-documentation)
- [Project Structure](#-project-structure)
- [Deployment](#-deployment)
- [Contributing](#-contributing)
- [License](#-license)

## âœ¨ Features

### Core Functionality
- ğŸ¤– **Multi-LLM Support**: Choose between OpenAI GPT, Anthropic Claude, or Google Gemini
- ğŸ“š **RAG Pipeline**: Semantic search with context-aware responses
- ğŸ’¬ **Real-time Chat**: Interactive chat interface with conversation history
- ğŸ“„ **Document Management**: Upload and manage knowledge base documents (PDF, TXT, DOCX, MD)
- ğŸ“Š **Analytics Dashboard**: Monitor usage, performance, and user satisfaction
- ğŸ” **Source Attribution**: See which documents were used to generate responses

### Advanced Features
- **Vector Database**: ChromaDB for fast semantic search
- **Smart Chunking**: Intelligent document splitting for optimal retrieval
- **Conversation Memory**: Multi-turn conversations with context preservation
- **Multi-format Support**: PDF, TXT, DOCX, Markdown document processing
- **File Upload**: Drag-and-drop interface with real-time processing
- **Chat History**: Browse and continue previous conversations
- **Feedback System**: Rate AI responses to improve quality
- **Analytics**: Time-series data, topic analysis, document usage stats

### User Experience
- ğŸ¨ **Modern UI**: Clean, responsive interface built with Tailwind CSS
- ğŸ“± **Mobile Responsive**: Works seamlessly on all devices
- âš¡ **Fast Performance**: Optimized for speed with React Query caching
- ğŸ”„ **Real-time Updates**: Instant feedback and status updates
- ğŸ¯ **Intuitive Navigation**: Easy-to-use sidebar navigation

## ğŸ›  Tech Stack

### Backend
- **Framework**: FastAPI (Python)
- **AI/ML**: LangChain, OpenAI, Anthropic, Google Gemini
- **Vector DB**: ChromaDB
- **Database**: PostgreSQL with SQLAlchemy ORM
- **Embeddings**: HuggingFace Sentence Transformers
- **Document Processing**: PyPDF, python-docx, markdown

### Frontend
- **Framework**: React 18 with TypeScript
- **Build Tool**: Vite
- **Styling**: Tailwind CSS
- **State Management**: TanStack React Query
- **Routing**: React Router v6
- **Charts**: Recharts
- **HTTP Client**: Axios
- **UI Components**: Custom components with Lucide icons

### DevOps
- **Containerization**: Docker & Docker Compose
- **Database Migrations**: Alembic
- **Environment Management**: python-dotenv

## ğŸ— Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend  â”‚
â”‚   (React)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ HTTP/REST API
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           FastAPI Backend                    â”‚
â”‚                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  REST API  â”‚  â”‚   RAG Service       â”‚   â”‚
â”‚  â”‚  Endpoints â”‚  â”‚  - LangChain        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚  - Multi-LLM        â”‚   â”‚
â”‚        â”‚         â”‚  - Prompt Templates â”‚   â”‚
â”‚        â”‚         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚        â”‚                â”‚                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚    Business Logic Services     â”‚        â”‚
â”‚  â”‚  - Document Processor           â”‚        â”‚
â”‚  â”‚  - Vector Store Manager         â”‚        â”‚
â”‚  â”‚  - Analytics Service            â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚        â”‚              â”‚                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚              â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚PostgreSQLâ”‚  â”‚  ChromaDB   â”‚
    â”‚  (Data)  â”‚  â”‚  (Vectors)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Getting Started

### Prerequisites

- **Python** 3.10 or higher
- **Node.js** 18 or higher
- **PostgreSQL** 13 or higher
- **API Keys** for at least one LLM provider (OpenAI, Anthropic, or Google)

### Installation

#### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/rag_system.git
cd rag_system
```

#### 2. Backend Setup

```bash
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Create .env file
cp .env.example .env

# Edit .env with your configuration
nano .env
```

**Required environment variables:**
```env
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/rag_system
GOOGLE_API_KEY=your_gemini_api_key_here
# Or use OpenAI/Anthropic
OPENAI_API_KEY=your_openai_key
ANTHROPIC_API_KEY=your_anthropic_key
```

#### 3. Database Setup

```bash
# Create PostgreSQL database
createdb rag_system

# Run migrations (tables will be created automatically on first run)
```

#### 4. Frontend Setup

```bash
cd ../frontend

# Install dependencies
npm install

# Create .env file
cp .env.example .env

# Edit if needed (default points to localhost:8000)
```

#### 5. Load Sample Documents

```bash
# Sample documents are in sample_documents/
# You can upload them through the UI after starting the application
```

### Running the Application

#### Start Backend (Terminal 1)

```bash
cd backend
source venv/bin/activate
python -m app.main

# Or use uvicorn directly:
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

Backend will be available at `http://localhost:8000`

#### Start Frontend (Terminal 2)

```bash
cd frontend
npm run dev
```

Frontend will be available at `http://localhost:5173`

## âš™ï¸ Configuration

### Backend Configuration

Edit `backend/.env`:

```env
# Database
DATABASE_URL=postgresql://user:password@host:port/database

# Vector Database
CHROMA_PERSIST_DIRECTORY=./data/vectordb

# LLM Provider (choose one or configure all)
DEFAULT_LLM_PROVIDER=google  # openai, anthropic, google
DEFAULT_MODEL=gemini-pro

# API Keys
GOOGLE_API_KEY=your_key
OPENAI_API_KEY=your_key
ANTHROPIC_API_KEY=your_key

# Application
DEBUG=True
CORS_ORIGINS=http://localhost:5173

# File Upload
MAX_FILE_SIZE=10485760  # 10MB
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
```

### Frontend Configuration

Edit `frontend/.env`:

```env
VITE_API_URL=http://localhost:8000
```

## ğŸ“– Usage

### 1. Upload Documents

1. Navigate to **Documents** page
2. Drag and drop files or click to select
3. Supported formats: PDF, TXT, DOCX, MD
4. Wait for processing to complete

### 2. Chat with AI

1. Go to **Chat** page
2. Type your question in the input box
3. View AI response with source attribution
4. Continue multi-turn conversations

### 3. View Analytics

1. Visit **Analytics** page
2. Monitor key metrics:
   - Total conversations and messages
   - Average ratings
   - Time-series trends
   - Popular topics

### 4. Browse History

1. Open **History** page
2. View all past conversations
3. Click to view full conversation
4. Continue previous chats or delete them

## ğŸ“š API Documentation

### Interactive API Docs

Once the backend is running, visit:

- **Swagger UI**: `http://localhost:8000/docs`
- **ReDoc**: `http://localhost:8000/redoc`

### Key Endpoints

#### Chat
```
POST /api/chat/
GET /api/chat/conversations
GET /api/chat/conversations/{id}
DELETE /api/chat/conversations/{id}
POST /api/chat/feedback
```

#### Documents
```
POST /api/documents/upload
GET /api/documents/
GET /api/documents/{id}
DELETE /api/documents/{id}
GET /api/documents/stats/overview
```

#### Analytics
```
GET /api/analytics/summary
GET /api/analytics/time-series?days=7
GET /api/analytics/top-topics?limit=10
GET /api/analytics/document-usage
```

## ğŸ“ Project Structure

```
rag_system/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/              # API endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py
â”‚   â”‚   â”‚   â”œâ”€â”€ documents.py
â”‚   â”‚   â”‚   â””â”€â”€ analytics.py
â”‚   â”‚   â”œâ”€â”€ core/             # Core configuration
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”‚   â””â”€â”€ database.py
â”‚   â”‚   â”œâ”€â”€ models/           # Database models
â”‚   â”‚   â”‚   â”œâ”€â”€ document.py
â”‚   â”‚   â”‚   â”œâ”€â”€ conversation.py
â”‚   â”‚   â”‚   â””â”€â”€ analytics.py
â”‚   â”‚   â”œâ”€â”€ schemas/          # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ services/         # Business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_provider.py
â”‚   â”‚   â”‚   â”œâ”€â”€ vector_store.py
â”‚   â”‚   â”‚   â”œâ”€â”€ rag_service.py
â”‚   â”‚   â”‚   â””â”€â”€ document_processor.py
â”‚   â”‚   â””â”€â”€ main.py           # FastAPI app
â”‚   â”œâ”€â”€ data/                 # Data storage
â”‚   â”‚   â”œâ”€â”€ documents/        # Uploaded files
â”‚   â”‚   â””â”€â”€ vectordb/         # ChromaDB data
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env.example
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/              # API client
â”‚   â”‚   â”œâ”€â”€ components/       # React components
â”‚   â”‚   â”œâ”€â”€ pages/            # Page components
â”‚   â”‚   â”œâ”€â”€ types/            # TypeScript types
â”‚   â”‚   â”œâ”€â”€ utils/            # Utility functions
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â””â”€â”€ main.tsx
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ .env.example
â”œâ”€â”€ sample_documents/         # Sample knowledge base
â”‚   â”œâ”€â”€ product_catalog.md
â”‚   â”œâ”€â”€ return_policy.md
â”‚   â”œâ”€â”€ warranty_terms.md
â”‚   â”œâ”€â”€ shipping_delivery.md
â”‚   â””â”€â”€ faq.md
â””â”€â”€ README.md
```

## ğŸš¢ Deployment

### Manual Deployment

#### Backend (Production)

```bash
# Install production dependencies
pip install gunicorn

# Run with gunicorn
gunicorn app.main:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
```

#### Frontend (Production)

```bash
# Build for production
npm run build

# Serve with nginx or any static server
# Build output is in dist/
```

### Environment Variables for Production

- Set `DEBUG=False`
- Use strong database credentials
- Configure proper CORS origins
- Use environment secrets management
- Enable HTTPS

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ™ Acknowledgments

- **LangChain** for the RAG framework
- **FastAPI** for the excellent web framework
- **React** and **Vite** for the frontend
- **OpenAI**, **Anthropic**, and **Google** for LLM APIs
- **ChromaDB** for vector storage

---

**Built with â¤ï¸ for Upwork Portfolio**

*This is a demonstration project showcasing full-stack RAG implementation with modern web technologies.*